{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Tuple\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from core.raft_stereo import RAFTStereo\n",
    "except ImportError:\n",
    "    import os\n",
    "    os.chdir(\"/RAFT-Stereo\")\n",
    "    from core.raft_stereo import RAFTStereo\n",
    "    \n",
    "FRPASS = \"frames_cleanpass\"\n",
    "from train_fusion.dataloader import StereoDataset, StereoDatasetArgs\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from fusion_args import FusionArgs\n",
    "args = FusionArgs()\n",
    "args.hidden_dims = [128, 128, 128]\n",
    "args.corr_levels = 4\n",
    "args.corr_radius = 4\n",
    "args.n_downsample = 3\n",
    "args.context_norm = \"batch\"\n",
    "args.n_gru_layers = 2\n",
    "args.shared_backbone = True\n",
    "args.mixed_precision = True\n",
    "args.corr_implementation = \"reg_cuda\"\n",
    "args.slow_fast_gru = False\n",
    "args.restore_ckpt = \"models/raftstereo-realtime.pth\"\n",
    "\n",
    "\n",
    "args.lr = 0.001\n",
    "args.train_iters = 7\n",
    "args.valid_iters = 12\n",
    "args.wdecay = 0.0001\n",
    "args.num_steps = 100000\n",
    "args.valid_steps = 1000\n",
    "args.name = \"StereoFusion\"\n",
    "args.batch_size = 4\n",
    "args.fusion = \"AFF\"\n",
    "args.shared_fusion = True\n",
    "args.freeze_backbone = []\n",
    "args.both_side_train= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(RAFTStereo(args)).cuda()\n",
    "model.load_state_dict(torch.load(args.restore_ckpt))\n",
    "model.eval()\n",
    "model = model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPARITY_MAX = 64\n",
    "\n",
    "\n",
    "def cv2img_to_torch(img: np.ndarray):\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.tensor(img).cuda().float().unsqueeze(0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_frame_spectral(frame_folder: str):\n",
    "    left = cv2.imread(os.path.join(frame_folder, \"left.png\"))\n",
    "    right = cv2.imread(os.path.join(frame_folder, \"right.png\"))\n",
    "    left = cv2img_to_torch(left)\n",
    "    right = cv2img_to_torch(right)\n",
    "    _, flow = model(left, right, iters=15, test_mode=True)\n",
    "    flow = -flow[0].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "    return flow\n",
    "\n",
    "\n",
    "def store_disparity(\n",
    "    frame_folder: str, channel: str, disp: np.ndarray, DISPARITY_MAX=64\n",
    "):\n",
    "    disparity_color = cv2.applyColorMap(\n",
    "        (np.clip(disp, 0, DISPARITY_MAX) / DISPARITY_MAX * 255.0).astype(np.uint8),\n",
    "        cv2.COLORMAP_MAGMA,\n",
    "    )\n",
    "    cv2.imwrite(os.path.join(frame_folder, channel, \"disparity.png\"), disparity_color)\n",
    "\n",
    "\n",
    "def process_frame(frame_folder: str, overwrite=False):\n",
    "    if (\n",
    "        not overwrite\n",
    "        and os.path.exists(os.path.join(frame_folder, \"rgb\", \"disparity.png\"))\n",
    "        and os.path.exists(os.path.join(frame_folder, \"nir\", \"disparity.png\"))\n",
    "    ):\n",
    "        return\n",
    "    disparity_rgb = process_frame_spectral(frame_folder + \"/rgb\")\n",
    "    disparity_nir = process_frame_spectral(frame_folder + \"/nir\")\n",
    "\n",
    "    disparity_max = max(disparity_rgb.max(), disparity_nir.max()) // 64 * 64\n",
    "    store_disparity(frame_folder, \"rgb\", disparity_rgb, disparity_max)\n",
    "    store_disparity(frame_folder, \"nir\", disparity_nir, disparity_max)\n",
    "    return disparity_rgb, disparity_nir\n",
    "\n",
    "\n",
    "def process_scene(folder: str):\n",
    "    frame_folders = [\n",
    "        os.path.join(folder, x)\n",
    "        for x in tqdm(os.listdir(folder))\n",
    "        if x.split(\"_\")[-1].isdigit()\n",
    "    ]\n",
    "    print(len(frame_folders))\n",
    "    frame_folders.sort()\n",
    "    for frame in tqdm(frame_folders):\n",
    "        try:\n",
    "            process_frame(frame)\n",
    "        except Exception as e:\n",
    "            print(frame)\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/bean/depth/09-04-18-40-09/18_40_08_851/post.npz\"\n",
    "post = np.load(PATH)\n",
    "print(post[\"transform\"])\n",
    "\n",
    "transform_mtx = post[\"transform\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_lidarpoints_to_image(\n",
    "        lidar_points: np.ndarray, width: int, height,\n",
    "        focal_length: float, cx: float, cy: float,\n",
    "    ):\n",
    "    '''\n",
    "    라이다 points 를 카메라 coordinate로 옮깁니다.\n",
    "    카메라 width, height 내부의 point만 반환합니다.\n",
    "    '''\n",
    "    transform_matrix = transform_mtx\n",
    "    lidar_points = lidar_points.reshape(-1, 3) * 1000\n",
    "\n",
    "    # 3D 라이다 포인트를 4xN 행렬로 변환\n",
    "\n",
    "    lidar_points = np.concatenate(\n",
    "        [lidar_points, np.ones((lidar_points.shape[0], 1))], axis=1\n",
    "    ).T\n",
    "\n",
    "    # 변환 행렬을 사용하여 라이다 포인트를 카메라 좌표계로 변환\n",
    "    # camera_points = transform_matrix @ lidar_points\n",
    "    camera_points = np.linalg.pinv(transform_matrix) @ lidar_points\n",
    "\n",
    "    # 카메라 좌표계의 3D 포인트를 2D 이미지 좌표로 변환\n",
    "    u = camera_points[0] * focal_length / camera_points[2] + cx\n",
    "    v = camera_points[1] * focal_length / camera_points[2] + cy\n",
    "    depth = camera_points[2]\n",
    "\n",
    "    camera_surface = np.stack([u, v, depth], axis=1)\n",
    "    lidar_points = lidar_points.T\n",
    "\n",
    "    csf = camera_surface[\n",
    "        (camera_surface[:, 0] > 0)\n",
    "        & (camera_surface[:, 0] < width)\n",
    "        & (camera_surface[:, 1] > 0)\n",
    "        & (camera_surface[:, 1] < height)\n",
    "        & (camera_surface[:, 2] > 0)\n",
    "    ]\n",
    "\n",
    "\n",
    "    csf = csf[np.argsort(csf[:, 2])[::-1]]\n",
    "    return csf\n",
    "    \n",
    "def render_2dpoint_to_image(\n",
    "        points: np.ndarray,  width: int, height: int, use_color: bool = True, MAX_DEPTH: float = 10000\n",
    "    ):\n",
    "    '''\n",
    "    projected 2d lidar points 를 하나의 이미지로 변환합니다.\n",
    "    '''\n",
    "    \n",
    "    if use_color:\n",
    "        colormap = cv2.applyColorMap(\n",
    "            np.linspace(0, 255, 256).astype(np.uint8), cv2.COLORMAP_MAGMA\n",
    "        )\n",
    "\n",
    "    canvas = (\n",
    "        np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        if use_color\n",
    "        else np.zeros((height, width), dtype=np.float32)\n",
    "    )\n",
    "    \n",
    "    if not use_color:\n",
    "        u = points[:, 0].astype(int)\n",
    "        v = points[:, 1].astype(int)\n",
    "        depth = points[:, 2]\n",
    "        u = np.clip(u, 0, width - 3)\n",
    "        v = np.clip(v, 0, height - 3)\n",
    "        \n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                canvas[v + i, u + j] = depth\n",
    "        \n",
    "        return canvas\n",
    "\n",
    "    for u, v, depth in points:\n",
    "        radius = 3\n",
    "        u = int(int(u) // 4 * 4)\n",
    "        v = int(int(v) // 4 * 4)\n",
    "        if use_color:\n",
    "            depth_color = int(np.clip(depth / MAX_DEPTH * 255, 0, 255))\n",
    "\n",
    "            # radius = int(depth / MAX_DEPTH * 10 + 5)\n",
    "            r, g, b = map(int, colormap[depth_color][0])\n",
    "            cv2.circle(canvas, (u, v), radius, (r, g, b), -1)\n",
    "        else:\n",
    "            for i in range(-radius, radius + 1):\n",
    "                for j in range(-radius, radius + 1):\n",
    "                    if (\n",
    "                        0 <= int(v) + i < height\n",
    "                        and 0 <= int(u) + j < width\n",
    "                        and np.linalg.norm([i, j]) <= radius\n",
    "                    ):\n",
    "                        canvas[int(v) + i, int(u) + j] = depth\n",
    "\n",
    "\n",
    "    colorbar = cv2.resize(colormap, (50, height))\n",
    "    return np.concatenate([canvas, colorbar], axis=1)\n",
    "\n",
    "        \n",
    "def disparity_to_depth(disparity: np.ndarray, focal_length: float, baseline: float):\n",
    "    '''\n",
    "    disparity map을 depth map으로 변환합니다\n",
    "    '''\n",
    "    disparity = disparity.astype(np.float32)\n",
    "    depth = focal_length * baseline / disparity\n",
    "    depth[depth < 0] = 0\n",
    "    depth[np.isnan(depth)] = 0\n",
    "    depth[np.isinf(depth)] = 0\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lidar_frame(lidar_points: np.ndarray, calibration: dict):\n",
    "    '''\n",
    "    라이다 포인트를 칼리브레이션을 바탕으로 처리합니다.\n",
    "    '''\n",
    "    focal_length: float = calibration[\"mtx_left\"][0,0]\n",
    "    cx: float = calibration[\"mtx_left\"][0,2]\n",
    "    cy: float = calibration[\"mtx_left\"][1,2]\n",
    "\n",
    "    image_size: Tuple[int, int] = calibration[\"image_size\"]\n",
    "    \n",
    "    lidar_camera_points = transform_lidarpoints_to_image(lidar_points, image_size[0], image_size[1], focal_length, cx, cy)\n",
    "    \n",
    "    return lidar_camera_points\n",
    "\n",
    "def process_lidar_h5file(h5file: str, overwrite: bool = False):\n",
    "    '''\n",
    "    h5file 내부의 모든 lidar points에 대해 카메라 좌표계로 변환하고, 이미지에 렌더링합니다.\n",
    "    '''\n",
    "    with h5py.File(h5file, \"a\") as f:\n",
    "        calibration = f[\"calibration\"].attrs\n",
    "        depth_median = 0\n",
    "        keys = list(f['frame'].keys())\n",
    "        if not overwrite and \"projected_points\" in f.require_group(f\"frame/{keys[-1]}\")[\"lidar\"]:\n",
    "            f.close()\n",
    "            return\n",
    "        for frame in tqdm(f[\"frame\"]):\n",
    "            \n",
    "            if not \"image_size\" in calibration:\n",
    "                image = Image.open(os.path.join(os.path.dirname(h5file), frame, \"rgb\",\"left.png\"))\n",
    "                calibration[\"image_size\"] = image.size\n",
    "            frame = f.require_group(f\"frame/{frame}\")\n",
    "            if \"projected_points\" in frame[\"lidar\"]:\n",
    "                continue\n",
    "            lidar_points = frame[\"lidar/points\"][:]\n",
    "            \n",
    "            lidar_projected_points = process_lidar_frame(lidar_points, calibration)\n",
    "            depth_median = np.max([depth_median, np.median(lidar_projected_points[:,2])])\n",
    "            if \"projected_points\" in frame[\"lidar\"]:\n",
    "                del frame[\"lidar/projected_points\"]\n",
    "            frame.create_dataset(\"lidar/projected_points\", data=lidar_projected_points)\n",
    "        \n",
    "        for frame in f[\"frame\"]:\n",
    "            if os.path.exists(os.path.join(os.path.dirname(h5file), frame, \"lidar.png\")):\n",
    "                continue\n",
    "            frame_group = f.require_group(f\"frame/{frame}\")\n",
    "            lidar_projected_points = frame_group[\"lidar/projected_points\"][:]\n",
    "            width, height = calibration[\"image_size\"]\n",
    "            rendered_image = render_2dpoint_to_image(lidar_projected_points, width,height, use_color=True, MAX_DEPTH=depth_median*5)\n",
    "            scene_folder = os.path.dirname(h5file)\n",
    "            cv2.imwrite(os.path.join(scene_folder, frame, \"lidar.png\"), rendered_image)\n",
    "            \n",
    "            # disparity_rgb = frame_group[\"disparity\"][\"rgb\"][:]\n",
    "            # focal_length = calibration[\"mtx_left\"][0,0]\n",
    "            # depth = disparity_to_depth(disparity_rgb, focal_length, np.linalg.norm(calibration[\"T\"][:]))\n",
    "            # depth = (np.clip(depth, 0, depth_median*5) / (depth_median*5) * 255.0).astype(np.uint8)\n",
    "            # depth = cv2.applyColorMap(depth, cv2.COLORMAP_MAGMA)\n",
    "            # cv2.imwrite(os.path.join(scene_folder, frame, \"depth.png\"), depth)\n",
    "        f.close()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_create_fig_png(\n",
    "    scene_folder: str,\n",
    "    frame_id: str,\n",
    "    frame: h5py.Group,\n",
    "    focal_length: float,\n",
    "    baseline: float,\n",
    "    use_numpy=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Frame에 대해 3x3 이미지 그리드를 생성합니다.\n",
    "    각 채널의 Stereo Image, Disparity, Depth 그리고 Lidar Projected Depth를 표시합니다.\n",
    "    \"\"\"\n",
    "    rgb_left = cv2.imread(os.path.join(scene_folder, frame_id, \"rgb\", \"left.png\"))\n",
    "    rgb_right = cv2.imread(os.path.join(scene_folder, frame_id, \"rgb\", \"right.png\"))\n",
    "    nir_left = cv2.imread(os.path.join(scene_folder, frame_id, \"nir\", \"left.png\"))\n",
    "    nir_right = cv2.imread(os.path.join(scene_folder, frame_id, \"nir\", \"right.png\"))\n",
    "    rgb_disparity = frame[\"disparity/rgb\"][:]\n",
    "    nir_disparity = frame[\"disparity/nir\"][:]\n",
    "\n",
    "    ########### Mis aligned frame remove\n",
    "    if rgb_disparity.mean() < 64 and nir_disparity.mean() > 64:\n",
    "        return\n",
    "\n",
    "    rgb_depth = disparity_to_depth(rgb_disparity, focal_length, baseline)\n",
    "    nir_depth = disparity_to_depth(nir_disparity, focal_length, baseline)\n",
    "    lidar_depth = frame[\"lidar/projected_points\"][:]\n",
    "\n",
    "    if use_numpy:\n",
    "        fig = frame_create_fig_png_numpy(\n",
    "            (rgb_left, rgb_right, rgb_disparity),\n",
    "            (nir_left, nir_right, nir_disparity),\n",
    "            lidar_depth,\n",
    "            focal_length, baseline\n",
    "        )\n",
    "        cv2.imwrite(os.path.join(scene_folder, frame_id, \"fig.png\"), fig)\n",
    "        return\n",
    "        # Prepare layout for 3x3 image grid\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(25, 15))\n",
    "\n",
    "    depth_max = min(\n",
    "        max(20000, max(np.median(rgb_depth), np.median(nir_depth)) * 3), 50000\n",
    "    )\n",
    "    disparity_max = min(rgb_disparity.max(), nir_disparity.max()) * 0.8\n",
    "\n",
    "    # First row: RGB images\n",
    "    axs[0, 0].imshow(cv2.cvtColor(rgb_left, cv2.COLOR_BGR2RGB))\n",
    "    axs[0, 0].set_title(\"RGB Left\")\n",
    "    axs[0, 0].axis(\"off\")\n",
    "\n",
    "    axs[0, 1].imshow(cv2.cvtColor(rgb_right, cv2.COLOR_BGR2RGB))\n",
    "    axs[0, 1].set_title(\"RGB Right\")\n",
    "    axs[0, 1].axis(\"off\")\n",
    "\n",
    "    # RGB Disparity with magma colormap\n",
    "    im_rgb_disp = axs[0, 2].imshow(\n",
    "        np.clip(rgb_disparity, 0, disparity_max),\n",
    "        cmap=\"magma\",\n",
    "        vmin=0,\n",
    "        vmax=disparity_max,\n",
    "    )\n",
    "    axs[0, 2].set_title(\"RGB Disparity\")\n",
    "    fig.colorbar(im_rgb_disp, ax=axs[0, 2])\n",
    "    axs[0, 2].axis(\"off\")\n",
    "\n",
    "    # Second row: NIR images\n",
    "    axs[1, 0].imshow(cv2.cvtColor(nir_left, cv2.COLOR_BGR2RGB))\n",
    "    axs[1, 0].set_title(\"NIR Left\")\n",
    "    axs[1, 0].axis(\"off\")\n",
    "\n",
    "    axs[1, 1].imshow(cv2.cvtColor(nir_right, cv2.COLOR_BGR2RGB))\n",
    "    axs[1, 1].set_title(\"NIR Right\")\n",
    "    axs[1, 1].axis(\"off\")\n",
    "\n",
    "    # NIR Disparity with magma colormap\n",
    "    im_nir_disp = axs[1, 2].imshow(\n",
    "        np.clip(nir_disparity, 0, disparity_max),\n",
    "        cmap=\"magma\",\n",
    "        vmin=0,\n",
    "        vmax=disparity_max,\n",
    "    )\n",
    "    axs[1, 2].set_title(\"NIR Disparity\")\n",
    "    fig.colorbar(im_nir_disp, ax=axs[1, 2])\n",
    "    axs[1, 2].axis(\"off\")\n",
    "    rgb_depth[rgb_disparity < 1] = 0\n",
    "    nir_depth[nir_disparity < 1] = 0\n",
    "    # Third row: Depth images\n",
    "    im_rgb_depth = axs[2, 0].imshow(\n",
    "        np.clip(rgb_depth, 0, depth_max), cmap=\"magma\", vmin=0, vmax=depth_max\n",
    "    )\n",
    "    axs[2, 0].set_title(\"RGB Depth\")\n",
    "    fig.colorbar(im_rgb_depth, ax=axs[2, 0])\n",
    "    axs[2, 0].axis(\"off\")\n",
    "    im_nir_depth = axs[2, 1].imshow(\n",
    "        np.clip(nir_depth, 0, depth_max), cmap=\"magma\", vmin=0, vmax=depth_max\n",
    "    )\n",
    "    axs[2, 1].set_title(\"NIR Depth\")\n",
    "    fig.colorbar(im_nir_depth, ax=axs[2, 1])\n",
    "    axs[2, 1].axis(\"off\")\n",
    "    # Lidar depth (point cloud projected)\n",
    "    u, v = lidar_depth[:, 0], -lidar_depth[:, 1]\n",
    "    z = lidar_depth[:, 2]\n",
    "    sc = axs[2, 2].scatter(\n",
    "        u, v, c=np.clip(z, 0, depth_max), cmap=\"magma\", vmin=0, vmax=depth_max\n",
    "    )\n",
    "    axs[2, 2].set_title(\"Lidar Depth\")\n",
    "    fig.colorbar(sc, ax=axs[2, 2])\n",
    "    axs[2, 2].axis(\"off\")\n",
    "    # Display the full layout\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    plt.savefig(os.path.join(scene_folder, frame_id, \"fig.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def process_h5file_create_figs(h5path: str):\n",
    "    \"\"\"\n",
    "    h5file의 모든 frame에 대해 fig png 이미지들을 생성합니다.\n",
    "    \"\"\"\n",
    "    scene_id = os.path.dirname(h5path).split(\"/\")[-1]\n",
    "    with h5py.File(h5path, \"r\") as f:\n",
    "        focal_length = f[\"calibration\"].attrs[\"mtx_left\"][0, 0]\n",
    "        baseline = np.linalg.norm(f[\"calibration\"].attrs[\"T\"][:])\n",
    "        for frame_id in f[\"frame\"]:\n",
    "            frame_create_fig_png(\n",
    "                os.path.dirname(h5path),\n",
    "                frame_id,\n",
    "                f[\"frame\"].require_group(frame_id),\n",
    "                focal_length,\n",
    "                baseline,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "rgb_label = None\n",
    "nir_label = None\n",
    "colorbar_disparity = None\n",
    "\n",
    "def frame_create_fig_png_numpy(\n",
    "    rgb_tuple: Tuple[np.ndarray, np.ndarray, np.ndarray],\n",
    "    nir_tuple: Tuple[np.ndarray, np.ndarray, np.ndarray],\n",
    "    lidar_depth: np.ndarray,\n",
    "    focal_length : float, baseline: float,\n",
    "):\n",
    "    rgb_left, rgb_right, rgb_disparity = rgb_tuple\n",
    "    H,W = rgb_left.shape[:2]\n",
    "    nir_left, nir_right, nir_disparity = nir_tuple\n",
    "    rgb_disparity = rgb_disparity[:H, :W]\n",
    "    nir_disparity = nir_disparity[:H, :W]\n",
    "    #depth_max = min(max(20000, max(np.median(rgb_depth), np.median(nir_depth)) * 3), 50000)\n",
    "    disparity_max = min(rgb_disparity.max(), nir_disparity.max()) * 0.8\n",
    "    rgb_disparity_color = cv2.applyColorMap(\n",
    "        (np.clip(rgb_disparity, 0, disparity_max) / disparity_max * 255.0).astype(\n",
    "            np.uint8\n",
    "        ),\n",
    "        cv2.COLORMAP_MAGMA,\n",
    "    )\n",
    "    nir_disparity_color = cv2.applyColorMap(\n",
    "        (np.clip(nir_disparity, 0, disparity_max) / disparity_max * 255.0).astype(\n",
    "            np.uint8\n",
    "        ),\n",
    "        cv2.COLORMAP_MAGMA,\n",
    "    )\n",
    "    rgb_concat = np.concatenate([rgb_left, rgb_right, rgb_disparity_color], axis=1)\n",
    "    nir_concat = np.concatenate([nir_left, nir_right, nir_disparity_color], axis=1)\n",
    "    \n",
    "    colorbar_disparity = np.linspace(0, 255,256).reshape(256,1).astype(np.uint8)\n",
    "    colorbar_disparity = cv2.applyColorMap(colorbar_disparity, cv2.COLORMAP_MAGMA)\n",
    "    colorbar_disparity = cv2.resize(colorbar_disparity, (50, rgb_left.shape[0]))\n",
    "    colorbar_disparity_text = np.zeros((rgb_left.shape[0], 100, 3), dtype=np.uint8) + 255\n",
    "    for i in range(0, rgb_left.shape[0], 100):\n",
    "        cv2.putText(\n",
    "            colorbar_disparity_text,\n",
    "            str(int(i / rgb_left.shape[0] * disparity_max)),\n",
    "            (10, i+15),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            1,\n",
    "        )\n",
    "    colorbar_depth_text = np.zeros((rgb_left.shape[0], 100, 3), dtype=np.uint8) + 255\n",
    "    for i in range(100, rgb_left.shape[0], 100):\n",
    "        cv2.putText(\n",
    "            colorbar_depth_text,\n",
    "            str(round(focal_length * baseline / (   i / rgb_left.shape[0] * disparity_max)/1000,1)) + \"m\",\n",
    "            (10, i+15),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            1,\n",
    "        )\n",
    "    rgb_concat = np.concatenate([rgb_concat, colorbar_disparity, colorbar_disparity_text], axis=1)\n",
    "    nir_concat = np.concatenate([nir_concat, colorbar_disparity, colorbar_disparity_text], axis=1)\n",
    "    lidar_depth[:,2] = focal_length * baseline / lidar_depth[:,2]\n",
    "    lidar_disparity = render_2dpoint_to_image(lidar_depth, rgb_left.shape[1], rgb_left.shape[0], use_color=False)\n",
    "    lidar_disparity_color = cv2.applyColorMap(\n",
    "        (np.clip(lidar_disparity, 0, disparity_max) / disparity_max * 255.0).astype(np.uint8),\n",
    "        cv2.COLORMAP_MAGMA,\n",
    "    )\n",
    "    rgb_concat = np.concatenate([rgb_concat, lidar_disparity_color, colorbar_disparity, colorbar_depth_text], axis=1)\n",
    "    nir_padding = np.zeros((nir_concat.shape[0], rgb_concat.shape[1] - nir_concat.shape[1], 3), dtype=np.uint8) + 255\n",
    "    nir_concat = np.concatenate([nir_concat, nir_padding], axis=1)\n",
    "    global rgb_label, nir_label\n",
    "    if rgb_label is None:\n",
    "        rgb_label = np.zeros((100, rgb_concat.shape[1], 3), dtype=np.uint8) + 255\n",
    "        cv2.putText(rgb_label, \"RGB Left\", (W // 2, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "        cv2.putText(rgb_label, \"RGB Right\", (W // 2 * 3, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "        cv2.putText(rgb_label, \"RGB Disparity\", (W // 2 * 5, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "        cv2.putText(rgb_label, \"Lidar Depth\", (W // 2 * 7, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "        nir_label = np.zeros((100, rgb_concat.shape[1], 3), dtype=np.uint8) + 255\n",
    "        cv2.putText(nir_label, \"NIR Left\", (W // 2, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "        cv2.putText(nir_label, \"NIR Right\", (W // 2 * 3, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "        cv2.putText(nir_label, \"NIR Disparity\", (W // 2 * 5, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "        \n",
    "\n",
    "    fig = np.concatenate([rgb_label, rgb_concat, nir_label, nir_concat], axis=0)\n",
    "    return fig\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "from typing import Union\n",
    "from IPython.display import Video, display\n",
    "\n",
    "def save_video(image_paths: list[str], video_path, fps=5):\n",
    "    '''\n",
    "    image_paths로 읽어 온 이미지 파일들을 순서대로 비디오 파일로 저장합니다.\n",
    "    image_paths: 이미지 파일 경로 리스트\n",
    "    video_path: 저장할 비디오 파일 경로\n",
    "    fps: 초당 프레임 수\n",
    "    '''\n",
    "    print(image_paths[0])\n",
    "    height, width = cv2.imread(image_paths[0]).shape[:2]\n",
    "    # 비디오 파일 쓰기 설정\n",
    "    fourcc = cv2.VideoWriter.fourcc(*'mp4v')  # 코덱 설정\n",
    "    os.makedirs(os.path.dirname(video_path), exist_ok=True)\n",
    "    out = cv2.VideoWriter(video_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    for img in tqdm(image_paths):\n",
    "        img = img.replace(\"frames_cleanpass\", \"plot\")\n",
    "        if not os.path.exists(img):\n",
    "            break\n",
    "        image = cv2.imread(img)\n",
    "        out.write( image)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"비디오가 저장되었습니다: {video_path}\")\n",
    "\n",
    "\n",
    "def process_h5_plt_video(h5file: str, create_fig=False):\n",
    "    '''\n",
    "    h5file의 모든 frame에 대해 fig.png 이미지들을 하나의 비디오로 저장합니다.\n",
    "    '''\n",
    "    with h5py.File(h5file, \"r\")  as f:\n",
    "        frame_ids = list(f[\"frame\"].keys())\n",
    "        frame_id_filtered = []\n",
    "        focal_length = f[\"calibration\"].attrs[\"mtx_left\"][0,0]\n",
    "        baseline = np.linalg.norm(f[\"calibration\"].attrs[\"T\"][:])\n",
    "        if create_fig:\n",
    "            fig_create_threads = []\n",
    "            for idx, frame_id in enumerate(tqdm(frame_ids)):\n",
    "                thread = threading.Thread(target=frame_create_fig_png, args=(os.path.dirname(h5file), frame_id, f[\"frame\"].require_group(frame_id), focal_length, baseline,  True))\n",
    "                thread.start()\n",
    "                fig_create_threads.append(thread)\n",
    "                if len(fig_create_threads) >= 6 or idx == len(frame_ids) - 1:\n",
    "                    for thread in fig_create_threads:\n",
    "                        thread.join()\n",
    "                    fig_create_threads = []        \n",
    "        for frame_id in frame_ids:\n",
    "            if not os.path.exists(os.path.join(os.path.dirname(h5file), frame_id, \"fig.png\")):\n",
    "                continue\n",
    "            if cv2.imread(os.path.join(os.path.dirname(h5file), frame_id, \"fig.png\")) is None:\n",
    "                continue\n",
    "            frame_id_filtered.append(frame_id)\n",
    "        image_paths = [os.path.join(os.path.dirname(h5file), x, \"fig.png\") for x in frame_id_filtered]\n",
    "        save_video(image_paths, h5file.replace(\".hdf5\", \".mp4\"))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_depth_lidar_loss(frame: h5py.Group, focal_length: float, baseline: float):\n",
    "    disparity_rgb = frame[\"disparity/rgb\"][:]\n",
    "    disparity_nir = frame[\"disparity/nir\"][:]\n",
    "    projected_points = frame[\"lidar/projected_points\"][:]\n",
    "\n",
    "    u = projected_points[:, 0]\n",
    "    v = projected_points[:, 1]\n",
    "    z = focal_length * baseline / projected_points[:, 2]\n",
    "    depth_rgb = disparity_rgb[v.astype(int), u.astype(int)].squeeze()\n",
    "    depth_nir = disparity_nir[v.astype(int), u.astype(int)].squeeze()\n",
    "    \n",
    "    rsme_rgb = np.sqrt(np.mean((depth_rgb - z) ** 2))\n",
    "    rsme_nir = np.sqrt(np.mean((depth_nir - z) ** 2))\n",
    "    mae_rgb = np.mean(np.abs(depth_rgb - z))\n",
    "    mae_nir = np.mean(np.abs(depth_nir - z))\n",
    "    return (rsme_rgb, rsme_nir), (mae_rgb, mae_nir)\n",
    "\n",
    "\n",
    "def process_depth_loss_h5file(h5file: str, overwrite_loss=False):\n",
    "    \"\"\"\n",
    "    h5file의 모든 frame에 대해\n",
    "    raft stereo로 계산한 depth와 라이다 depth의 차이를 계산합니다.\n",
    "    rsme와 mae를 반환합니다.\n",
    "    \"\"\"\n",
    "    with h5py.File(h5file, \"a\") as f:\n",
    "        frame_ids = list(f[\"frame\"].keys())\n",
    "        focal_length = f[\"calibration\"].attrs[\"mtx_left\"][0, 0]\n",
    "        baseline = np.linalg.norm(f[\"calibration\"].attrs[\"T\"][:])\n",
    "        __rsme_rgb = []\n",
    "        __rsme_nir = []\n",
    "        __mae_rgb = []\n",
    "        __mae_nir = []\n",
    "        if not overwrite_loss and \"rsme_rgb\" in f.attrs:\n",
    "            f.close()\n",
    "            return\n",
    "        for frame_id in tqdm(frame_ids):\n",
    "            frame = f.require_group(f\"frame/{frame_id}\")\n",
    "            if \"lidar/projected_points\" not in frame:\n",
    "                continue\n",
    "            (rsme_rgb, rsme_nir), (mae_rgb, mae_nir) = stereo_depth_lidar_loss(\n",
    "                frame, focal_length, baseline\n",
    "            )\n",
    "            frame[\"disparity/rgb\"].attrs[\"rsme\"] = rsme_rgb\n",
    "            frame[\"disparity/nir\"].attrs[\"rsme\"] = rsme_nir\n",
    "            frame[\"disparity/rgb\"].attrs[\"mae\"] = mae_rgb\n",
    "            frame[\"disparity/nir\"].attrs[\"mae\"] = mae_nir\n",
    "            __rsme_rgb.append(rsme_rgb)\n",
    "            __rsme_nir.append(rsme_nir)\n",
    "            __mae_rgb.append(mae_rgb)\n",
    "            __mae_nir.append(mae_nir)\n",
    "            print(f\"{frame_id} RSME RGB: {rsme_rgb:.2f} RSME NIR: {rsme_nir:.2f}\")\n",
    "            print(f\"{frame_id} MAE RGB: {mae_rgb:.2f} MAE NIR: {mae_nir:.2f}\")\n",
    "        f.attrs[\"rsme_rgb\"] = np.mean(__rsme_rgb)\n",
    "        f.attrs[\"rsme_nir\"] = np.mean(__rsme_nir)\n",
    "        f.attrs[\"mae_rgb\"] = np.mean(__mae_rgb)\n",
    "        f.attrs[\"mae_nir\"] = np.mean(__mae_nir)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_disparity_h5file(h5file: str, overwrite=False):\n",
    "    '''\n",
    "    h5file의 모든 frame에 대해\n",
    "    Raft Stereo 모델을 사용하여 disparity를 추출하고 h5 파일에 저장합니다.\n",
    "    disparity를 color map으로 변환하여 png 파일로 저장합니다.\n",
    "    '''\n",
    "    with h5py.File(h5file, \"a\")  as f:\n",
    "        frame_ids = list(f[\"frame\"].keys())\n",
    "        if not overwrite and \"disparity\" in f[\"frame\"][frame_ids[-1]]:\n",
    "            f.close()\n",
    "            return\n",
    "        for frame_id in tqdm(frame_ids):\n",
    "            frame = f.require_group(f\"frame/{frame_id}\")\n",
    "            if not overwrite and \"disparity\" in frame:\n",
    "                continue\n",
    "            output = process_frame(os.path.join(os.path.dirname(h5file), frame_id))\n",
    "            if output is None:\n",
    "                continue\n",
    "            disparity_rgb, disparity_nir = output\n",
    "            \n",
    "            frame.create_dataset(\"disparity/rgb\", data=disparity_rgb)\n",
    "            frame.create_dataset(\"disparity/nir\", data=disparity_nir)\n",
    "            if not \"disparity\" in frame:\n",
    "                continue\n",
    "            disparity_rgb = frame[\"disparity/rgb\"][:]\n",
    "            disparity_nir = frame[\"disparity/nir\"][:]\n",
    "            if disparity_nir.mean() > 64 and disparity_rgb.mean() < 64:\n",
    "                frame.attrs[\"align_error\"] = True\n",
    "                print(f\"A frame {frame_id} has an alignment error\")\n",
    "            else:\n",
    "                frame.attrs[\"align_error\"] = False\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_h5file_all(\n",
    "    h5file: str,\n",
    "    overwrite_disparity=False,\n",
    "    overwrite_loss=False,\n",
    "    overwrite_plot=False,\n",
    "    overwrite_lidar=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    h5file에 대해 disparity, plot, lidar를 모두 처리합니다.\n",
    "    \"\"\"\n",
    "    process_disparity_h5file(h5file, overwrite=overwrite_disparity)\n",
    "    process_lidar_h5file(h5file, overwrite=overwrite_lidar)\n",
    "    process_depth_loss_h5file(h5file, overwrite_loss=overwrite_loss)\n",
    "    if overwrite_plot or not os.path.exists(h5file.replace(\".hdf5\", \".mp4\")):\n",
    "        process_h5_plt_video(h5file, create_fig=True)\n",
    "\n",
    "    print(f\"Finished processing {h5file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [x for x in os.listdir(\"/bean/depth\") if x.startswith(\"09-10\")]\n",
    "for folder in folders:\n",
    "    print(f\"Processing {folder}\")\n",
    "    h5files = [os.path.join(\"/bean/depth\", folder, x) for x in os.listdir(os.path.join(\"/bean/depth\", folder)) if x.endswith(\".hdf5\")]\n",
    "    h5files.sort(key=lambda x: int(os.path.basename(x).split(\".\")[0]))\n",
    "    for h5file in h5files:\n",
    "        print(f\"Processing {h5file}\")\n",
    "        process_lidar_h5file(h5file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FOLDERS = [x for x in os.listdir(\"/bean/depth\") if os.path.isdir( os.path.join(\"/bean/depth\",x))]\n",
    "FOLDERS = [x for x in FOLDERS if x.startswith(\"09-10\")]\n",
    "h5files_pending = []\n",
    "for folder in FOLDERS:\n",
    "    print(folder)\n",
    "    h5files = os.listdir(os.path.join(\"/bean/depth\",folder))\n",
    "    h5files = [x for x in h5files if x.endswith(\".hdf5\")]\n",
    "    h5files.sort(key=lambda x : int(x.split('.')[0]) )\n",
    "    for h5 in h5files:\n",
    "        h5files_pending.append(os.path.join(\"/bean/depth\",folder,h5))\n",
    "print(len(h5files_pending))\n",
    "for h5 in tqdm(h5files_pending):\n",
    "    if os.path.exists(h5.replace(\".hdf5\", \".mp4\")):\n",
    "        continue\n",
    "    process_h5_plt_video(h5, create_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2310 - 2160 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_h5file_all(\"/bean/depth/09-09-20-04-34/0.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
