{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
    "try:\n",
    "    from core.raft_stereo import RAFTStereo\n",
    "except ImportError:\n",
    "    import os\n",
    "    os.chdir(\"/RAFT-Stereo\")\n",
    "    from core.raft_stereo import RAFTStereo\n",
    "    \n",
    "FRPASS = \"frames_cleanpass\"\n",
    "from train_fusion.dataloader import StereoDataset, StereoDatasetArgs\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from fusion_args import FusionArgs\n",
    "args = FusionArgs()\n",
    "args.hidden_dims = [128, 128, 128]\n",
    "args.corr_levels = 4\n",
    "args.corr_radius = 4\n",
    "args.n_downsample = 3\n",
    "args.context_norm = \"batch\"\n",
    "args.n_gru_layers = 2\n",
    "args.shared_backbone = True\n",
    "args.mixed_precision = True\n",
    "args.corr_implementation = \"reg_cuda\"\n",
    "args.slow_fast_gru = False\n",
    "args.restore_ckpt = \"models/raftstereo-realtime.pth\"\n",
    "\n",
    "\n",
    "args.lr = 0.001\n",
    "args.train_iters = 7\n",
    "args.valid_iters = 12\n",
    "args.wdecay = 0.0001\n",
    "args.num_steps = 100000\n",
    "args.valid_steps = 1000\n",
    "args.name = \"ColorFusion\"\n",
    "args.batch_size = 8\n",
    "args.fusion = \"AFF\"\n",
    "args.shared_fusion = True\n",
    "args.freeze_backbone = []\n",
    "args.both_side_train= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from color_fusion_model import RGBNIRFusionNet\n",
    "from rgb_thermal_fusion_net import RGBThermalFusionNet\n",
    "\n",
    "from encoding.parallel import DataParallelModel, DataParallelCriterion\n",
    "\n",
    "device_ids=(0,1,2,3,4,5)\n",
    "raft_model = DataParallelModel(RAFTStereo(args),device_ids=device_ids, output_device=device_ids[0]).to('cuda')\n",
    "raft_model.load_state_dict(torch.load(args.restore_ckpt),  strict=False)\n",
    "raft_model.eval()\n",
    "raft_model.module.freeze_bn()\n",
    "raft_model = raft_model.module\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_disparity(left: torch.Tensor, right: torch.Tensor):\n",
    "        if left.shape[-3] == 1:\n",
    "            left = left.repeat(1, 3, 1, 1)\n",
    "            right = right.repeat(1, 3, 1, 1)\n",
    "        _, flow = raft_model(left, right, test_mode=True)\n",
    "        return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_fusion.my_h5_dataloader import MyH5DataSet\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "dataset = MyH5DataSet( frame_cache=True)\n",
    "cnt = len(dataset)\n",
    "train_cnt = int(cnt * 0.9)\n",
    "valid_cnt = cnt - train_cnt\n",
    "print(cnt)\n",
    "dataset_train = MyH5DataSet(id_list = dataset.frame_id_list[:train_cnt])\n",
    "dataset_valid = MyH5DataSet(id_list = dataset.frame_id_list[train_cnt:])\n",
    "train_loader = DataLoader(dataset_train, batch_size=args.batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "valid_loader = DataLoader(dataset_valid, batch_size=args.batch_size, shuffle=False, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rgb_thermal_fusion_net import RGBThermalFusionNet\n",
    "import matplotlib.pyplot as plt\n",
    "from color_fusion_model import RGBNIRFusionNet\n",
    "fusion_model = nn.DataParallel(RGBNIRFusionNet()).cuda()\n",
    "#fusion_model = nn.DataParallel(RGBThermalFusionNet(hidden_dim=16)).cuda()\n",
    "fusion_model.module.load_state_dict(torch.load(\"checkpoints/22550_ColorFusion.pth\"))\n",
    "#fusion_model.load_state_dict(torch.load(\"interrupted_model.pth\"))\n",
    "fusion_model = fusion_model.module\n",
    "\n",
    "def loss_fn_detph_gt(flow: torch.Tensor, target_gt: torch.Tensor):\n",
    "    gt_u = target_gt[:, :, 1].long()\n",
    "    gt_v = target_gt[:, :, 0].long()\n",
    "    gt_u = torch.clamp(gt_u, 0, flow.shape[-2] - 1)\n",
    "    gt_v = torch.clamp(gt_v, 0, flow.shape[-1] - 1)\n",
    "    B, N = gt_u.shape\n",
    "    batch_indices = torch.arange(B).view(B, 1).expand(B, N).to(flow.device)\n",
    "    target_pred = -flow[batch_indices, :, gt_u, gt_v].squeeze()\n",
    "\n",
    "    target_depth = target_gt[:, :, 2]\n",
    "    depth_loss = torch.sqrt(torch.mean((target_pred - target_depth) ** 2, dim=1))\n",
    "\n",
    "    return depth_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "train_input = next(train_iter)\n",
    "fusion_model.eval()\n",
    "image1, image2, image3, image4, depth = [x.cuda() for x in train_input]\n",
    "with torch.no_grad():\n",
    "    fused_input1 = torch.cat([image1, image3], dim=1)  # image1: RGB, image3: Thermal\n",
    "    fused_input2 = torch.cat([image2, image4], dim=1)\n",
    "    image_fusion_1 = fusion_model(fused_input1)\n",
    "    image_fusion_2 = fusion_model(fused_input2)\n",
    "print(image_fusion_1.min(), image_fusion_1.max(), image_fusion_1.mean())\n",
    "image_fusion_1 -= image_fusion_1.min()\n",
    "image_fusion_2 -= image_fusion_2.min()\n",
    "# image_fusion_1 = image_fusion_1 / image_fusion_2.max() * 255\n",
    "# image_fusion_2 = image_fusion_2 / image_fusion_2.max() * 255\n",
    "print(image_fusion_1.min(), image_fusion_1.max(), image_fusion_1.mean())\n",
    "with torch.no_grad():\n",
    "    disparity_rgb = -compute_disparity(image1, image2)\n",
    "    disparity_nir = -compute_disparity(image3, image4)\n",
    "    disparity_fusion = -compute_disparity(image_fusion_1, image_fusion_2)\n",
    "    loss_rgb = loss_fn_detph_gt(-disparity_rgb, depth).cpu()\n",
    "    loss_nir = loss_fn_detph_gt(-disparity_nir, depth).cpu()\n",
    "    loss_fusion = loss_fn_detph_gt(-disparity_fusion, depth).cpu()\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(loss_rgb)\n",
    "    plt.plot(loss_nir)\n",
    "    plt.plot(loss_fusion)\n",
    "    plt.legend([\"rgb\",\"nir\",\"fusion\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "batch_size = image1.shape[0]\n",
    "for idx in range(batch_size):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(image1[idx].permute(1,2,0).cpu().numpy().astype(np.uint8))\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(image3[idx].permute(1,2,0).cpu().numpy().astype(np.uint8), cmap=\"gray\")\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(image_fusion_1[idx].permute(1,2,0).cpu().numpy().astype(np.uint8))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    for vmax in [12, 64, 128]:\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.subplot(141)\n",
    "        plt.imshow(disparity_rgb[idx,0].cpu().numpy(), cmap=\"magma\", vmin=0, vmax=vmax)\n",
    "        plt.subplot(142)\n",
    "        plt.imshow(disparity_nir[idx,0].cpu().numpy(), cmap=\"magma\", vmin=0, vmax=vmax)\n",
    "        plt.subplot(143)\n",
    "        plt.imshow(disparity_fusion[idx,0].cpu().numpy(), cmap=\"magma\", vmin=0, vmax=vmax)\n",
    "        ax = plt.subplot(144)\n",
    "\n",
    "        lidar_depth = depth[idx].cpu().numpy()\n",
    "        u, v = lidar_depth[:, 0], -lidar_depth[:, 1]\n",
    "        z = lidar_depth[:, 2]\n",
    "        sc = plt.scatter(\n",
    "            u, v, c=z, cmap=\"magma\", vmin = 0, vmax = vmax\n",
    "        )\n",
    "        plt.gca().set_aspect(540/720) \n",
    "        plt.colorbar(sc, ax=ax)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from core.raft_stereo import RAFTStereo\n",
    "except ImportError:\n",
    "    import os\n",
    "    os.chdir(\"/RAFT-Stereo\")\n",
    "    from core.raft_stereo import RAFTStereo\n",
    "!torchrun --nproc_per_node=6 color_fusion_train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
